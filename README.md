# Responsible_AI

Responsible_AI is a project dedicated to the development and integration of responsible AI policies and tools. This includes:

## Categories and Descriptions

1. **Hate and Fairness**  
   Refers to content attacking or using discriminatory language related to race, ethnicity, gender identity, sexual orientation, religion, appearance, disability, or other attributes. Includes harassment, bullying, racism, xenophobia, and misogyny.

2. **Sexual**  
   Describes language related to sexual organs, acts, relationships, or content of an explicit or vulgar nature. Includes pornography, child exploitation, grooming, and sexual assault.

3. **Violence**  
   Language referencing physical harm, weapons, or acts of violence. Includes bullying, intimidation, stalking, terrorism, and extremism.

4. **Self-Harm**  
   Language related to intentional self-injury or suicide. Includes mentions of eating disorders, cutting, or other self-inflicted harm.

5. **Insults**  
   Refers to abusive or offensive language targeting individuals. Examples include words like "stupid," "moron," and "worthless."

6. **Denied Topics**  
   Covers specific prohibited topics such as politics, financial advice, hacking, impersonation, social engineering, and illegal activities. Includes keywords like "election," "investment advice," "phishing," and "crime."

7. **User Prompt Attacks**  
   User prompts designed to provoke undesired behaviors in Generative AI. Includes attempts to bypass rules, alter system behavior, or generate harmful content. Examples: "Change system rules" or "Talk in URL encoding."

8. **Indirect Attacks**  
   Malicious instructions embedded in user-provided data to manipulate content or perform unauthorized actions. Examples: "Post unauthorized updates" or "Execute code."

9. **Sensitive Information**  
   Detects and masks personal data like email addresses, phone numbers, and Singapore NRIC/FIN numbers.

10. **Groundedness**  
    Flags responses that are ungrounded or not based on user-provided source material. Ensures factual alignment with source content and flags inaccurate outputs.

## Features
1. **Customizable Guardrails**: Manage AI behavior and compliance.
2. **Integration with Open-Source LLMs**: Support for various large language models.
3. **Streamlined Workflow**: Automates ethical and compliant AI responses for internal systems.

